{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "https://www.youtube.com/watch?v=WEV61GmmPrk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiddens states -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNNs) use hidden states to retain information from previous time steps, allowing them to use past outputs as inputs to process sequential data. In an RNN, each time step processes the current input and combines it with information from a hidden state that was generated at the previous time step. This hidden state serves as a memory, enabling the network to retain context and dependencies over time.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. **Input and Hidden State Combination**: At each time step \\( t \\), the RNN receives the current input \\( x_t \\) and the hidden state from the previous time step \\( h_{t-1} \\).\n",
    "2. **Updating the Hidden State**: The RNN updates its hidden state \\( h_t \\) based on both \\( x_t \\) and \\( h_{t-1} \\), typically using a function like:\n",
    "   \\[\n",
    "   h_t = f(W \\cdot x_t + U \\cdot h_{t-1} + b)\n",
    "   \\]\n",
    "   where \\( W \\) and \\( U \\) are weights, \\( b \\) is a bias term, and \\( f \\) is an activation function (e.g., tanh or ReLU).\n",
    "3. **Output**: The updated hidden state \\( h_t \\) is used as the input for the next time step and can also be used to produce an output \\( y_t \\) if needed. \n",
    "\n",
    "This process allows RNNs to capture temporal dependencies in the data, as each hidden state effectively \"remembers\" information from previous steps, enabling the network to use this memory when predicting future outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.plainenglish.io/rnn-mathematical-intuition-11f33de62eca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utills import ALL_LETTERS, N_LETTERS\n",
    "from utills import load_data, line_to_tensor, letter_to_tensor, random_training_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size+hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
    "\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)\n",
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(N_LETTERS, n_hidden, n_categories)\n",
    "\n",
    "# one step\n",
    "input_tensor = letter_to_tensor('A')\n",
    "hidden_tensor = rnn.init_hidden()\n",
    "\n",
    "output, next_hidden = rnn(input_tensor, hidden_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(next_hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output.size())\n",
    "#print(next_hidden.size())\n",
    "\n",
    "# whole sequence/name\n",
    "input_tensor = line_to_tensor('Albert')\n",
    "hidden_tensor = rnn.init_hidden()\n",
    "\n",
    "output, next_hidden = rnn(input_tensor[0], hidden_tensor)\n",
    "#print(output.size())\n",
    "#print(next_hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#\n",
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]\n",
    "\n",
    "print(category_from_output(output))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "plot_steps, print_steps = 1000, 5000\n",
    "n_iters = 100000\n",
    "for i in range(n_iters):\n",
    "    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)\n",
    "    \n",
    "    output, loss = train(line_tensor, category_tensor)\n",
    "    current_loss += loss \n",
    "    \n",
    "    if (i+1) % plot_steps == 0:\n",
    "        all_losses.append(current_loss / plot_steps)\n",
    "        current_loss = 0\n",
    "        \n",
    "    if (i+1) % print_steps == 0:\n",
    "        guess = category_from_output(output)\n",
    "        correct = \"CORRECT\" if guess == category else f\"WRONG ({category})\"\n",
    "        print(f\"{i+1} {(i+1)/n_iters*100} {loss:.4f} {line} / {guess} {correct}\")\n",
    "        \n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "def predict(input_line):\n",
    "    print(f\"\\n> {input_line}\")\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "        guess = category_from_output(output)\n",
    "        print(guess)\n",
    "\n",
    "\n",
    "while True:\n",
    "    sentence = input(\"Input:\")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "    \n",
    "    predict(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
