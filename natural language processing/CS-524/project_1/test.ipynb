{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1 Embedding-based Plot Analysis\n",
    "Goals and the Task\n",
    "You will use word embeddings to perform a text analysis of crime novels. The aim is to analyze the plot, characters, and events and develop predictive models to forecast potential outcomes in the story (e.g., identifying the criminal or key plot twists) based on semantic relationships in the text.\n",
    "\n",
    "Steps\n",
    "Data Preparation and Data Engineering\n",
    "\n",
    "   - Choose up to three crime novels from Project Guttenberg for your assigned author.\n",
    "\n",
    "   - Perform text preprocessing — normalization and tokenization of your choice\n",
    "\n",
    "Word Embedding Models\n",
    "\n",
    "   - Train or load pre-trained word embeddings using models such as:\n",
    "\n",
    "     - Word2Vec\n",
    "\n",
    "     - GloVe\n",
    "\n",
    "     - FastText\n",
    "\n",
    "   - Fine-tune these embeddings on the selected texts, if necessary, to capture story-specific language.\n",
    "\n",
    "Analysis of Narrative Structure\n",
    "\n",
    "   - Character and Event Representation: Use word embeddings to analyze relationships between key characters, places, and events in the text.\n",
    "\n",
    "     - Compute similarity scores between characters to understand their semantic proximity in the text.\n",
    "\n",
    "     - Identify clusters of semantically similar words to find patterns related to crime and investigation.\n",
    "\n",
    "     - Visualize the resulting word embeddings using t-SNE or PCA, focusing on terms relevant to crime novels (e.g., \"detective\", \"murder\", “<murder weapon>\").\n",
    "\n",
    "Predictive Analysis\n",
    "\n",
    "   - Based on the patterns observed in embeddings, attempt to predict the outcome of the novel. Consider:\n",
    "\n",
    "     - Who the criminal might be: Can you predict which character will be the criminal based on their interactions, dialogue, and proximity to keywords like \"murder\", \"crime\", \"evidence\", etc.?\n",
    "\n",
    "     - Critical plot twists: Identify key plot shifts and predict if a major event is going to occur based on word co-occurrence or a sudden change in word embedding distances.\n",
    "\n",
    "   - Create features from your embeddings (e.g., embedding averages over chapters, cosine similarity between key events and characters) and train a simple classifier (e.g., logistic regression or SVM) to predict important events.\n",
    "\n",
    "Evaluation\n",
    "\n",
    "   - Compare your predictions with the actual outcome of the novels.\n",
    "\n",
    "   - Write an analysis reflecting on:\n",
    "\n",
    "     - The accuracy of the predictions.\n",
    "\n",
    "     - The interpretability of word embeddings in representing narrative structures.\n",
    "\n",
    "     - Challenges faced and improvements that could be made to the predictive model.\n",
    "\n",
    " \n",
    "\n",
    "Resources\n",
    "Pre-trained Word Embeddings\n",
    "  - Word2VecLinks to an external site.\n",
    "\n",
    "  - GloVeLinks to an external site.\n",
    "\n",
    "  - FastTextLinks to an external site.\n",
    "\n",
    "  - Word Embeddings in SpaCyLinks to an external site.\n",
    "\n",
    "  - Word Embeddings in Hugging FaceLinks to an external site.\n",
    "\n",
    " \n",
    "\n",
    "Optional Challenges\n",
    "- Implement your own word embedding model using Word2Vec on a custom corpus.\n",
    "\n",
    "- Incorporate character dialogue as a feature to analyze which characters drive the narrative through their conversations.\n",
    "\n",
    "- Use sequence models like LSTM or transformers to enhance predictive capabilities for outcome forecasting.\n",
    "\n",
    " \n",
    "\n",
    "Good luck, and enjoy exploring the intersection of word embeddings and computational linguistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
